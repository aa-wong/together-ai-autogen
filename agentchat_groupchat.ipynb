{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `autogen-agentchat`:\n",
    "```bash\n",
    "pip install autogen-agentchat~=0.2\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat~=0.2 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat[together]~=0.2) (0.2.37)\n",
      "Requirement already satisfied: diskcache in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (5.6.3)\n",
      "Requirement already satisfied: docker in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (7.1.0)\n",
      "Requirement already satisfied: flaml in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.53.0)\n",
      "Requirement already satisfied: packaging in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (24.1)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2.9.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (0.8.0)\n",
      "Requirement already satisfied: together>=1.2 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from autogen-agentchat[together]~=0.2) (1.3.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2.23.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (3.10.10)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (0.2.0)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (3.16.1)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (18.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (0.9.0)\n",
      "Requirement already satisfied: typer<0.13,>=0.9 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from together>=1.2->autogen-agentchat[together]~=0.2) (0.12.5)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from docker->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from tiktoken->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen-agentchat~=0.2->autogen-agentchat[together]~=0.2) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->together>=1.2->autogen-agentchat[together]~=0.2) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from rich<14.0.0,>=13.8.1->together>=1.2->autogen-agentchat[together]~=0.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from rich<14.0.0,>=13.8.1->together>=1.2->autogen-agentchat[together]~=0.2) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from typer<0.13,>=0.9->together>=1.2->autogen-agentchat[together]~=0.2) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together>=1.2->autogen-agentchat[together]~=0.2) (0.1.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/aaronwong/miniforge3/envs/autogen/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.3->together>=1.2->autogen-agentchat[together]~=0.2) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"autogen-agentchat[together]~=0.2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\n",
    "            \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    "            # \"gpt-4o-mini\"\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
    ":::\n",
    "````\n",
    "\n",
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,\n",
    "        \"work_dir\": \"groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=\"Technical expert in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Generate some ideas for an AI startup\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Product_manager\n",
      "\u001b[0m\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Here are some innovative AI startup ideas:\n",
      "\n",
      "1. **Personalized Mental Health Assistant**: Develop an AI-powered chatbot that uses natural language processing (NLP) to offer personalized mental health advice, mood tracking, and stress management techniques.\n",
      "\n",
      "2. **AI-Powered Virtual Wardrobe**: Create an AI-driven virtual try-on platform that allows users to upload pictures of themselves and virtually try on clothes, accessories, and hairstyles.\n",
      "\n",
      "3. **Intelligent Home Maintenance**: Develop an AI-powered home maintenance platform that uses machine learning to detect potential issues, provide repair recommendations, and connect homeowners with local contractors.\n",
      "\n",
      "4. **AI-Driven Education Platform**: Create an AI-powered learning platform that uses adaptive learning algorithms to personalize educational content, offer real-time feedback, and provide teachers with data-driven insights.\n",
      "\n",
      "5. **AI-Powered Job Matching**: Develop an AI-driven job matching platform that uses machine learning to match job seekers with relevant job openings based on their skills, experience, and preferences.\n",
      "\n",
      "6. **AI-Driven Cybersecurity**: Create an AI-powered cybersecurity platform that uses machine learning to detect and prevent cyber threats, predict potential vulnerabilities, and provide real-time alerts.\n",
      "\n",
      "7. **Virtual Event Planning**: Develop an AI-powered event planning platform that uses machine learning to help plan and execute events, including venue selection, catering, and entertainment.\n",
      "\n",
      "8. **AI-Powered Financial Planning**: Create an AI-driven financial planning platform that uses machine learning to provide personalized investment advice, retirement planning, and budgeting recommendations.\n",
      "\n",
      "9. **AI-Driven Healthcare Diagnosis**: Develop an AI-powered healthcare diagnosis platform that uses machine learning to analyze medical images, diagnose diseases, and provide treatment recommendations.\n",
      "\n",
      "10. **AI-Powered Language Learning**: Create an AI-powered language learning platform that uses machine learning to provide personalized language lessons, real-time feedback, and conversational practice.\n",
      "\n",
      "11. **AI-Driven Supply Chain Optimization**: Develop an AI-powered supply chain optimization platform that uses machine learning to predict demand, optimize inventory, and streamline logistics.\n",
      "\n",
      "12. **AI-Powered Customer Service**: Create an AI-powered customer service platform that uses machine learning to provide personalized support, answer frequently asked questions, and route complex issues to human representatives.\n",
      "\n",
      "13. **AI-Driven Predictive Maintenance**: Develop an AI-powered predictive maintenance platform that uses machine learning to predict equipment failures, schedule maintenance, and reduce downtime.\n",
      "\n",
      "14. **AI-Powered Travel Planning**: Create an AI-powered travel planning platform that uses machine learning to provide personalized travel recommendations, book flights and hotels, and offer real-time travel alerts.\n",
      "\n",
      "15. **AI-Driven Social Media Monitoring**: Develop an AI-powered social media monitoring platform that uses machine learning to track brand mentions, analyze sentiment, and provide real-time alerts.\n",
      "\n",
      "These ideas are just a starting point, and you can refine them based on your interests, expertise, and market demand.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Together.AI exception occurred: Error code: 500 - {\"message\": \"Internal server error\", \"type_\": \"server_error\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/oai/together.py:158\u001b[0m, in \u001b[0;36mTogetherClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtogether_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/together/resources/chat/completions.py:141\u001b[0m, in \u001b[0;36mChatCompletions.create\u001b[0;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m parameter_payload \u001b[38;5;241m=\u001b[39m ChatCompletionRequest(\n\u001b[1;32m    117\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    118\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    139\u001b[0m )\u001b[38;5;241m.\u001b[39mmodel_dump(exclude_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m response, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTogetherRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/together/abstract/api_requestor.py:249\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    243\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    244\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[1;32m    245\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    246\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    247\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/together/abstract/api_requestor.py:632\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 632\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    639\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/together/abstract/api_requestor.py:701\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(resp, rcode, stream_error\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Error code: 500 - {\"message\": \"Internal server error\", \"type_\": \"server_error\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate some ideas for an AI startup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# type exit to terminate the chat\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:1114\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m   1116\u001b[0m     summary_method,\n\u001b[1;32m   1117\u001b[0m     summary_args,\n\u001b[1;32m   1118\u001b[0m     recipient,\n\u001b[1;32m   1119\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:748\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    746\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 748\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:914\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:2068\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2068\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2070\u001b[0m         log_event(\n\u001b[1;32m   2071\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2076\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2077\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/groupchat.py:1171\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[0;32m-> 1171\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[43mgroupchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[1;32m   1173\u001b[0m         iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/groupchat.py:565\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[0;34m(self, last_speaker, selector)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_agent(last_speaker)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/groupchat.py:743\u001b[0m, in \u001b[0;36mGroupChat._auto_select_speaker\u001b[0;34m(self, last_speaker, selector, messages, agents)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_selection_transforms\u001b[38;5;241m.\u001b[39madd_to_agent(speaker_selection_agent)\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# Run the speaker selection chat\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchecking_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_selection_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't use caching for the speaker selection chat\u001b[39;49;00m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limiting the chat to the number of attempts, including the initial one\u001b[39;49;00m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker_auto_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Base silence on the verbose attribute\u001b[39;49;00m\n\u001b[1;32m    751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_speaker_selection_result(result, last_speaker, agents)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:1107\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1107\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:748\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    746\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 748\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:914\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:2068\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2068\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2070\u001b[0m         log_event(\n\u001b[1;32m   2071\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2076\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2077\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:1436\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1435\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m-> 1436\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:1455\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 1455\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/oai/client.py:777\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_throttle_api_calls(i)\n\u001b[1;32m    776\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m--> 777\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APITimeoutError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    779\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/autogen/lib/python3.10/site-packages/autogen/oai/together.py:160\u001b[0m, in \u001b[0;36mTogetherClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    158\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtogether_params)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTogether.AI exception occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m together_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# Read in the chunks as they stream\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Together.AI exception occurred: Error code: 500 - {\"message\": \"Internal server error\", \"type_\": \"server_error\"}"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Generate some ideas for an AI startup\"\n",
    ")\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Explore the utilization of large language models in automated group chat scenarios, where agents perform tasks collectively, demonstrating how they can be configured, interact with each other, and retrieve specific information from external resources.",
   "tags": [
    "orchestration",
    "group chat"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
